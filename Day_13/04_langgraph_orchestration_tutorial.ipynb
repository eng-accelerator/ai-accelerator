{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ•¸ï¸ LangGraph Orchestration Tutorial - Advanced Multi-Agent Workflows\n",
    "\n",
    "Welcome to the comprehensive tutorial for understanding **advanced multi-agent orchestration** using LangGraph, inspired by the Orion AI Agent System! This tutorial demonstrates how to build sophisticated AI workflows that coordinate multiple specialized agents.\n",
    "\n",
    "## ğŸ¯ What You'll Learn\n",
    "\n",
    "- Core concepts of graph-based AI orchestration\n",
    "- Building stateful multi-agent workflows\n",
    "- Agent coordination and message passing\n",
    "- Conditional execution and decision nodes\n",
    "- Error handling and recovery in complex workflows\n",
    "- State management across agent interactions\n",
    "\n",
    "## ğŸš€ Tutorial Approach\n",
    "\n",
    "This is a **standalone educational tutorial** that demonstrates the concepts and techniques used in multi-agent orchestration. We'll build simplified versions of key components to understand how they work, similar to the Orion LangGraph orchestrator.\n",
    "\n",
    "## ğŸ“š Prerequisites\n",
    "\n",
    "- Completion of Tutorials 1 & 2 (GitHub Integration and AI Generation)\n",
    "- Basic understanding of state machines and graph theory\n",
    "- OpenRouter API key for AI model access\n",
    "- Python knowledge with async/await concepts\n",
    "\n",
    "## ğŸ”§ LangGraph Overview\n",
    "\n",
    "LangGraph enables building **stateful, multi-actor applications** with LLMs:\n",
    "- **Cyclic flows**: Beyond simple chains to complex decision trees\n",
    "- **Controllability**: Precise control over agent interactions\n",
    "- **Persistence**: Maintain state across multiple interactions\n",
    "- **Human-in-the-loop**: Support for human oversight and intervention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Setup and Environment\n",
    "\n",
    "Let's start by setting up our environment and importing the necessary components for LangGraph orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Current working directory: /Users/ishandutta/Documents/code/ai-accelerator/orion\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for LangGraph orchestration tutorial\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional, TypedDict, Annotated\n",
    "from enum import Enum\n",
    "from openai import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "print(f\"ğŸ“ Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”‘ Environment Configuration\n",
    "\n",
    "Let's ensure our OpenRouter API key is configured for multi-agent AI operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ Orchestrator configuration loaded:\n",
      "   â€¢ Default model: openai/gpt-4o-mini\n",
      "   â€¢ Specialized agents: 3\n",
      "   â€¢ Max iterations: 6\n"
     ]
    }
   ],
   "source": [
    "# Check if OpenRouter API key is configured\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# Configuration for our orchestration system\n",
    "ORCHESTRATOR_CONFIG = {\n",
    "    \"default_model\": \"openai/gpt-4o-mini\",\n",
    "    \"specialized_models\": {\n",
    "        \"code_generator\": \"openai/gpt-4o-mini\",\n",
    "        \"code_reviewer\": \"openai/gpt-4o-mini\",\n",
    "        \"task_classifier\": \"openai/gpt-4o-mini\",\n",
    "    },\n",
    "    \"max_iterations\": 6,\n",
    "    \"timeout_seconds\": 300,\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ”§ Orchestrator configuration loaded:\")\n",
    "print(f\"   â€¢ Default model: {ORCHESTRATOR_CONFIG['default_model']}\")\n",
    "print(f\"   â€¢ Specialized agents: {len(ORCHESTRATOR_CONFIG['specialized_models'])}\")\n",
    "print(f\"   â€¢ Max iterations: {ORCHESTRATOR_CONFIG['max_iterations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Building Our Simplified LangGraph System\n",
    "\n",
    "Let's create a simplified version of LangGraph's core concepts to understand how orchestration works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ Base orchestration framework defined!\n",
      "ğŸ“‹ Core components:\n",
      "   â€¢ WorkflowState: Manages data flow between agents\n",
      "   â€¢ AgentType: Defines specialized agent types\n",
      "   â€¢ BaseAgent: Foundation for all specialized agents\n"
     ]
    }
   ],
   "source": [
    "# State management for our orchestration system\n",
    "class WorkflowState(TypedDict):\n",
    "    \"\"\"State that gets passed between agents in our workflow.\"\"\"\n",
    "\n",
    "    task_description: str\n",
    "    current_step: str\n",
    "    messages: List[Dict[str, Any]]\n",
    "    generated_files: List[Dict[str, str]]\n",
    "    errors: List[str]\n",
    "    metadata: Dict[str, Any]\n",
    "    completed_agents: List[str]\n",
    "    next_agent: Optional[str]\n",
    "\n",
    "\n",
    "class AgentType(Enum):\n",
    "    \"\"\"Types of agents in our orchestration system.\"\"\"\n",
    "\n",
    "    TASK_CLASSIFIER = \"task_classifier\"\n",
    "    CODE_GENERATOR = \"code_generator\"\n",
    "    CODE_REVIEWER = \"code_reviewer\"\n",
    "    FILE_MANAGER = \"file_manager\"\n",
    "    ORCHESTRATOR = \"orchestrator\"\n",
    "\n",
    "\n",
    "class BaseAgent:\n",
    "    \"\"\"Base agent class that all specialized agents inherit from.\"\"\"\n",
    "\n",
    "    def __init__(self, agent_type: AgentType, model: str, api_key: str):\n",
    "        self.agent_type = agent_type\n",
    "        self.model = model\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            default_headers={\"X-Title\": f\"Orion {agent_type.value} Agent\"},\n",
    "        )\n",
    "        self.execution_history = []\n",
    "\n",
    "    async def execute(self, state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Execute this agent's functionality and update state.\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            print(f\"ğŸ¤– {self.agent_type.value} starting execution...\")\n",
    "\n",
    "            # Call the agent-specific logic\n",
    "            result_state = await self._process(state)\n",
    "\n",
    "            # Update metadata\n",
    "            execution_time = time.time() - start_time\n",
    "\n",
    "            result_state[\"metadata\"][\n",
    "                f\"{self.agent_type.value}_execution_time\"\n",
    "            ] = execution_time\n",
    "            \n",
    "            result_state[\"completed_agents\"].append(self.agent_type.value)\n",
    "\n",
    "            print(f\"âœ… {self.agent_type.value} completed in {execution_time:.2f}s\")\n",
    "            return result_state\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Agent {self.agent_type.value} failed: {str(e)}\"\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "\n",
    "            state[\"errors\"].append(error_msg)\n",
    "            return state\n",
    "\n",
    "    async def _process(self, state: WorkflowState) -> WorkflowState:\n",
    "        \"\"\"Override this method in subclasses for agent-specific logic.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement _process method\")\n",
    "\n",
    "\n",
    "print(\"ğŸ—ï¸ Base orchestration framework defined!\")\n",
    "print(\"ğŸ“‹ Core components:\")\n",
    "print(\"   â€¢ WorkflowState: Manages data flow between agents\")\n",
    "print(\"   â€¢ AgentType: Defines specialized agent types\")\n",
    "print(\"   â€¢ BaseAgent: Foundation for all specialized agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Specialized Agent Implementations\n",
    "\n",
    "Let's create specific agents that demonstrate different capabilities in our orchestration system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskClassifierAgent(BaseAgent):\n",
    "    \"\"\"Agent that analyzes and classifies incoming tasks.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        super().__init__(AgentType.TASK_CLASSIFIER, ORCHESTRATOR_CONFIG[\"specialized_models\"][\"task_classifier\"], api_key)\n",
    "    \n",
    "    async def _process(self, state: WorkflowState) -> WorkflowState:\n",
    "        task_description = state[\"task_description\"]\n",
    "        \n",
    "        system_prompt = \"\"\"You are a task classification expert. Analyze the given task and determine:\n",
    "1. Task type (code_generation, code_review, file_management, research, etc.)\n",
    "2. Complexity level (simple, medium, complex)\n",
    "3. Required agents (list which agents should be involved)\n",
    "4. Estimated effort (low, medium, high)\n",
    "\n",
    "Respond with JSON in this format:\n",
    "{\n",
    "  \"task_type\": \"code_generation\",\n",
    "  \"complexity\": \"medium\", \n",
    "  \"required_agents\": [\"code_generator\", \"code_reviewer\"],\n",
    "  \"estimated_effort\": \"medium\",\n",
    "  \"reasoning\": \"Explanation of classification\",\n",
    "  \"next_agent\": \"code_generator\"\n",
    "}\"\"\"\n",
    "        \n",
    "        user_prompt = f\"Task to classify: {task_description}\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        classification = json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        # Update state with classification\n",
    "        state[\"current_step\"] = \"task_classified\"\n",
    "        state[\"metadata\"][\"task_classification\"] = classification\n",
    "        state[\"next_agent\"] = classification.get(\"next_agent\")\n",
    "        state[\"messages\"].append({\n",
    "            \"agent\": self.agent_type.value,\n",
    "            \"content\": f\"Task classified as {classification['task_type']} with {classification['complexity']} complexity\",\n",
    "            \"data\": classification\n",
    "        })\n",
    "        \n",
    "        return state\n",
    "\n",
    "class CodeGeneratorAgent(BaseAgent):\n",
    "    \"\"\"Agent specialized in generating code based on requirements.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        super().__init__(AgentType.CODE_GENERATOR, ORCHESTRATOR_CONFIG[\"specialized_models\"][\"code_generator\"], api_key)\n",
    "    \n",
    "    async def _process(self, state: WorkflowState) -> WorkflowState:\n",
    "        task_description = state[\"task_description\"]\n",
    "        classification = state[\"metadata\"].get(\"task_classification\", {})\n",
    "        \n",
    "        system_prompt = \"\"\"You are an expert software developer. Generate complete, production-ready code.\n",
    "        \n",
    "CRITICAL: You MUST respond with valid JSON in this exact structure:\n",
    "{\n",
    "  \"success\": true,\n",
    "  \"files\": [\n",
    "    {\"name\": \"filename.py\", \"content\": \"complete file content\"}\n",
    "  ],\n",
    "  \"reasoning\": \"Step-by-step explanation\",\n",
    "  \"dependencies\": [\"package1\", \"package2\"],\n",
    "  \"confidence\": 0.95,\n",
    "  \"next_action\": \"code_review\"\n",
    "}\n",
    "\n",
    "Requirements:\n",
    "- Complete, runnable code with all imports\n",
    "- Google-style docstrings and type hints  \n",
    "- Proper error handling\n",
    "- Follow PEP 8 style guidelines\"\"\"\n",
    "        \n",
    "        context = f\"Task: {task_description}\\nClassification: {classification}\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": context}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        generation_result = json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        # Update state with generated code\n",
    "        state[\"current_step\"] = \"code_generated\"\n",
    "        state[\"generated_files\"].extend(generation_result.get(\"files\", []))\n",
    "        state[\"metadata\"][\"generation_result\"] = generation_result\n",
    "        state[\"next_agent\"] = \"code_reviewer\" if generation_result.get(\"success\") else \"orchestrator\"\n",
    "        state[\"messages\"].append({\n",
    "            \"agent\": self.agent_type.value,\n",
    "            \"content\": f\"Generated {len(generation_result.get('files', []))} files with {generation_result.get('confidence', 0):.1%} confidence\",\n",
    "            \"data\": generation_result\n",
    "        })\n",
    "        \n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Specialized agents implemented!\n",
      "ğŸ¤– Available agents:\n",
      "   â€¢ TaskClassifierAgent: Analyzes and categorizes tasks\n",
      "   â€¢ CodeGeneratorAgent: Creates code based on requirements\n",
      "   â€¢ CodeReviewerAgent: Reviews and validates generated code\n",
      "   â€¢ FileManagerAgent: Saves generated files to disk\n"
     ]
    }
   ],
   "source": [
    "class CodeReviewerAgent(BaseAgent):\n",
    "    \"\"\"Agent that reviews and validates generated code.\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        super().__init__(\n",
    "            AgentType.CODE_REVIEWER,\n",
    "            ORCHESTRATOR_CONFIG[\"specialized_models\"][\"code_reviewer\"],\n",
    "            api_key,\n",
    "        )\n",
    "\n",
    "    async def _process(self, state: WorkflowState) -> WorkflowState:\n",
    "        generated_files = state[\"generated_files\"]\n",
    "\n",
    "        if not generated_files:\n",
    "            state[\"errors\"].append(\"No files to review\")\n",
    "            return state\n",
    "\n",
    "        # Check if this is a retry (second review attempt)\n",
    "        review_attempts = state[\"metadata\"].get(\"review_attempts\", 0)\n",
    "        is_retry = review_attempts >= 1\n",
    "        \n",
    "        # Update review attempt counter\n",
    "        state[\"metadata\"][\"review_attempts\"] = review_attempts + 1\n",
    "\n",
    "        if is_retry:\n",
    "            # On second attempt, automatically approve with a message\n",
    "            review_result = {\n",
    "                \"overall_quality\": \"fair\",\n",
    "                \"issues_found\": [],\n",
    "                \"strengths\": [\"Code meets basic requirements\"],\n",
    "                \"recommendations\": [\"Consider improvements in future iterations\"],\n",
    "                \"approved\": True,\n",
    "                \"confidence\": 0.8,\n",
    "                \"auto_approved\": True,\n",
    "                \"reason\": \"Automatically approved on retry to prevent infinite loops\"\n",
    "            }\n",
    "            \n",
    "            print(f\"ğŸ”„ Auto-approving code on retry attempt #{review_attempts + 1}\")\n",
    "        else:\n",
    "            # First attempt - do normal review\n",
    "            system_prompt = \"\"\"You are a senior code reviewer. Analyze the provided code and provide feedback.\n",
    "                            \n",
    "                    IMPORTANT: Be reasonably lenient in approval. Approve code that:\n",
    "                    - Is syntactically correct and runnable\n",
    "                    - Has basic error handling\n",
    "                    - Follows reasonable coding practices\n",
    "                    - Accomplishes the requested task\n",
    "                    \n",
    "                    Only reject code that has serious issues like:\n",
    "                    - Syntax errors or won't run\n",
    "                    - Security vulnerabilities\n",
    "                    - Completely wrong functionality\n",
    "                    - Missing critical error handling for dangerous operations\n",
    "                    \n",
    "                    Respond with JSON in this format:\n",
    "                    {\n",
    "                    \"overall_quality\": \"excellent|good|fair|poor\",\n",
    "                    \"issues_found\": [\n",
    "                        {\"severity\": \"high|medium|low\", \"description\": \"Issue description\", \"file\": \"filename.py\", \"suggestion\": \"How to fix\"}\n",
    "                    ],\n",
    "                    \"strengths\": [\"List of code strengths\"],\n",
    "                    \"recommendations\": [\"List of improvements\"],\n",
    "                    \"approved\": true,\n",
    "                    \"confidence\": 0.9\n",
    "                    }\"\"\"\n",
    "\n",
    "            # Prepare code for review\n",
    "            code_summary = \"\\n\\n\".join(\n",
    "                [\n",
    "                    f\"File: {file_info['name']}\\n{file_info['content'][:500]}...\"\n",
    "                    for file_info in generated_files\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"Code to review:\\n{code_summary}\"},\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "            )\n",
    "\n",
    "            review_result = json.loads(response.choices[0].message.content)\n",
    "\n",
    "        # Update state with review results\n",
    "        state[\"current_step\"] = \"code_reviewed\"\n",
    "        state[\"metadata\"][\"code_review\"] = review_result\n",
    "        state[\"next_agent\"] = (\n",
    "            \"file_manager\" if review_result.get(\"approved\", False) else \"code_generator\"\n",
    "        )\n",
    "        \n",
    "        # Enhanced message with retry info\n",
    "        approval_status = \"âœ… APPROVED\" if review_result.get(\"approved\", False) else \"âŒ REJECTED\"\n",
    "        retry_info = f\" (Auto-approved on retry)\" if is_retry and review_result.get(\"approved\", False) else \"\"\n",
    "        \n",
    "        state[\"messages\"].append(\n",
    "            {\n",
    "                \"agent\": self.agent_type.value,\n",
    "                \"content\": f\"Review completed - Quality: {review_result.get('overall_quality', 'unknown')}, {approval_status}{retry_info}\",\n",
    "                \"data\": review_result,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "class FileManagerAgent(BaseAgent):\n",
    "    \"\"\"Agent that manages file operations - creating, writing, and organizing files.\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        super().__init__(\n",
    "            AgentType.FILE_MANAGER,\n",
    "            ORCHESTRATOR_CONFIG[\"default_model\"],  # Use default model for file operations\n",
    "            api_key,\n",
    "        )\n",
    "\n",
    "    async def _process(self, state: WorkflowState) -> WorkflowState:\n",
    "        generated_files = state[\"generated_files\"]\n",
    "        \n",
    "        if not generated_files:\n",
    "            state[\"errors\"].append(\"No files to save\")\n",
    "            return state\n",
    "\n",
    "        # Determine output directory - use metadata if provided, otherwise create default\n",
    "        output_dir = state[\"metadata\"].get(\"output_directory\", \"/Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        files_created = []\n",
    "        files_failed = []\n",
    "\n",
    "        for file_info in generated_files:\n",
    "            filename = file_info.get(\"name\", \"unknown.py\")\n",
    "            content = file_info.get(\"content\", \"\")\n",
    "            \n",
    "            if not filename or not content:\n",
    "                files_failed.append(filename)\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                file_path = os.path.join(output_dir, filename)\n",
    "                \n",
    "                # Create subdirectories if filename includes path\n",
    "                dir_path = os.path.dirname(file_path)\n",
    "                if dir_path:\n",
    "                    os.makedirs(dir_path, exist_ok=True)\n",
    "                \n",
    "                with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(content)\n",
    "                \n",
    "                files_created.append(file_path)\n",
    "                print(f\"âœ… Created file: {file_path}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                files_failed.append(f\"{filename}: {str(e)}\")\n",
    "                print(f\"âŒ Failed to create {filename}: {e}\")\n",
    "\n",
    "        # Update state with file operation results\n",
    "        state[\"current_step\"] = \"files_saved\"\n",
    "        state[\"metadata\"][\"files_created\"] = files_created\n",
    "        state[\"metadata\"][\"files_failed\"] = files_failed\n",
    "        state[\"metadata\"][\"output_directory\"] = output_dir\n",
    "        state[\"next_agent\"] = \"end\"\n",
    "        \n",
    "        state[\"messages\"].append(\n",
    "            {\n",
    "                \"agent\": self.agent_type.value,\n",
    "                \"content\": f\"File operations completed - Created: {len(files_created)} files, Failed: {len(files_failed)} files in {output_dir}\",\n",
    "                \"data\": {\n",
    "                    \"files_created\": files_created,\n",
    "                    \"files_failed\": files_failed,\n",
    "                    \"output_directory\": output_dir\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Add any failures as errors\n",
    "        if files_failed:\n",
    "            for failure in files_failed:\n",
    "                state[\"errors\"].append(f\"File operation failed: {failure}\")\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "print(\"ğŸ¯ Specialized agents implemented!\")\n",
    "print(\"ğŸ¤– Available agents:\")\n",
    "print(\"   â€¢ TaskClassifierAgent: Analyzes and categorizes tasks\")\n",
    "print(\"   â€¢ CodeGeneratorAgent: Creates code based on requirements\")\n",
    "print(\"   â€¢ CodeReviewerAgent: Reviews and validates generated code\")\n",
    "print(\"   â€¢ FileManagerAgent: Saves generated files to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ•¸ï¸ LangGraph-Style Orchestrator\n",
    "\n",
    "Now let's build our main orchestrator that coordinates agent execution using graph-based workflow concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•¸ï¸ LangGraph-style orchestrator implemented!\n",
      "ğŸš€ Features:\n",
      "   â€¢ Graph-based execution flow\n",
      "   â€¢ Conditional agent routing\n",
      "   â€¢ State management across agents\n",
      "   â€¢ Error handling and recovery\n",
      "   â€¢ Execution history tracking\n",
      "   â€¢ File management and persistence\n"
     ]
    }
   ],
   "source": [
    "class SimpleLangGraphOrchestrator:\n",
    "    \"\"\"Simplified LangGraph-style orchestrator for multi-agent workflows.\"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.agents = {}\n",
    "        self.execution_graph = {}\n",
    "        self.workflow_history = []\n",
    "\n",
    "        # Initialize agents\n",
    "        self.agents[AgentType.TASK_CLASSIFIER] = TaskClassifierAgent(api_key)\n",
    "        self.agents[AgentType.CODE_GENERATOR] = CodeGeneratorAgent(api_key)\n",
    "        self.agents[AgentType.CODE_REVIEWER] = CodeReviewerAgent(api_key)\n",
    "        self.agents[AgentType.FILE_MANAGER] = FileManagerAgent(api_key)\n",
    "\n",
    "        # Define execution graph (workflow paths)\n",
    "        self.execution_graph = {\n",
    "            \"start\": \"task_classifier\",\n",
    "            \"task_classifier\": {\n",
    "                \"code_generation\": \"code_generator\",\n",
    "                \"default\": \"code_generator\",\n",
    "            },\n",
    "            \"code_generator\": \"code_reviewer\",\n",
    "            \"code_reviewer\": {\"approved\": \"file_manager\", \"rejected\": \"code_generator\"},\n",
    "            \"file_manager\": \"end\",\n",
    "            \"end\": None,\n",
    "        }\n",
    "\n",
    "    def create_initial_state(self, task_description: str, output_directory: str = None) -> WorkflowState:\n",
    "        \"\"\"Create initial workflow state for a new task.\"\"\"\n",
    "        return {\n",
    "            \"task_description\": task_description,\n",
    "            \"current_step\": \"start\",\n",
    "            \"messages\": [],\n",
    "            \"generated_files\": [],\n",
    "            \"errors\": [],\n",
    "            \"metadata\": {\n",
    "                \"start_time\": time.time(),\n",
    "                \"workflow_id\": f\"workflow_{int(time.time())}\",\n",
    "                \"output_directory\": output_directory or f\"/Users/ishandutta/Documents/code/ai-accelerator/orion/generated_{int(time.time())}\",\n",
    "            },\n",
    "            \"completed_agents\": [],\n",
    "            \"next_agent\": None,\n",
    "        }\n",
    "\n",
    "    def determine_next_agent(self, state: WorkflowState) -> Optional[str]:\n",
    "        \"\"\"Determine the next agent to execute based on current state.\"\"\"\n",
    "        current_step = state[\"current_step\"]\n",
    "\n",
    "        # Handle start state\n",
    "        if current_step == \"start\":\n",
    "            return \"task_classifier\"\n",
    "\n",
    "        # Handle task classification result\n",
    "        if current_step == \"task_classified\":\n",
    "            task_type = (\n",
    "                state[\"metadata\"]\n",
    "                .get(\"task_classification\", {})\n",
    "                .get(\"task_type\", \"code_generation\")\n",
    "            )\n",
    "            next_step = self.execution_graph.get(\"task_classifier\", {}).get(\n",
    "                task_type, \"code_generator\"\n",
    "            )\n",
    "            return next_step\n",
    "\n",
    "        # Handle code generation result\n",
    "        if current_step == \"code_generated\":\n",
    "            return \"code_reviewer\"\n",
    "\n",
    "        # Handle code review result\n",
    "        if current_step == \"code_reviewed\":\n",
    "            approved = state[\"metadata\"].get(\"code_review\", {}).get(\"approved\", False)\n",
    "            return \"file_manager\" if approved else \"code_generator\"\n",
    "\n",
    "        # Handle file manager completion\n",
    "        if current_step == \"files_saved\":\n",
    "            return \"end\"\n",
    "\n",
    "        return \"end\"\n",
    "\n",
    "    async def execute_workflow(self, task_description: str, output_directory: str = None) -> WorkflowState:\n",
    "        \"\"\"Execute a complete multi-agent workflow.\"\"\"\n",
    "        print(\"ğŸš€ Starting LangGraph-style workflow execution\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # Initialize state\n",
    "        state = self.create_initial_state(task_description, output_directory)\n",
    "        current_agent = \"task_classifier\"\n",
    "        iterations = 0\n",
    "\n",
    "        print(f\"ğŸ“‹ Task: {task_description}\")\n",
    "        print(f\"ğŸ†” Workflow ID: {state['metadata']['workflow_id']}\")\n",
    "        print(f\"ğŸ“ Output Directory: {state['metadata']['output_directory']}\")\n",
    "        print()\n",
    "\n",
    "        while (\n",
    "            current_agent\n",
    "            and current_agent != \"end\"\n",
    "            and iterations < ORCHESTRATOR_CONFIG[\"max_iterations\"]\n",
    "        ):\n",
    "            iterations += 1\n",
    "            print(f\"ğŸ”„ Iteration {iterations}: Executing {current_agent}\")\n",
    "\n",
    "            # Get the agent\n",
    "            agent_type = AgentType(current_agent)\n",
    "            agent = self.agents.get(agent_type)\n",
    "\n",
    "            if not agent:\n",
    "                error_msg = f\"Agent {current_agent} not found\"\n",
    "                print(f\"âŒ {error_msg}\")\n",
    "                state[\"errors\"].append(error_msg)\n",
    "                break\n",
    "\n",
    "            # Execute agent\n",
    "            try:\n",
    "                state = await agent.execute(state)\n",
    "\n",
    "                # Determine next agent\n",
    "                next_agent = self.determine_next_agent(state)\n",
    "\n",
    "                print(f\"ğŸ“ Current step: {state['current_step']}\")\n",
    "                print(f\"â¡ï¸ Next agent: {next_agent}\")\n",
    "                print()\n",
    "\n",
    "                current_agent = next_agent\n",
    "\n",
    "                # Break if errors occurred\n",
    "                if state[\"errors\"]:\n",
    "                    print(\"âš ï¸ Errors detected, stopping workflow\")\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Workflow execution failed: {str(e)}\"\n",
    "                print(f\"âŒ {error_msg}\")\n",
    "                state[\"errors\"].append(error_msg)\n",
    "                break\n",
    "\n",
    "        # Finalize workflow\n",
    "        state[\"metadata\"][\"end_time\"] = time.time()\n",
    "        state[\"metadata\"][\"total_time\"] = (\n",
    "            state[\"metadata\"][\"end_time\"] - state[\"metadata\"][\"start_time\"]\n",
    "        )\n",
    "        state[\"metadata\"][\"iterations\"] = iterations\n",
    "        state[\"current_step\"] = \"completed\" if not state[\"errors\"] else \"failed\"\n",
    "\n",
    "        # Store in history\n",
    "        self.workflow_history.append(state)\n",
    "\n",
    "        print(\"ğŸ Workflow execution completed\")\n",
    "        print(f\"â±ï¸ Total time: {state['metadata']['total_time']:.2f}s\")\n",
    "        print(f\"ğŸ”„ Iterations: {iterations}\")\n",
    "        print(f\"âœ… Status: {state['current_step']}\")\n",
    "        \n",
    "        # Show created files\n",
    "        files_created = state[\"metadata\"].get(\"files_created\", [])\n",
    "        if files_created:\n",
    "            print(f\"ğŸ“ Files created ({len(files_created)}):\")\n",
    "            for file_path in files_created:\n",
    "                print(f\"   â€¢ {file_path}\")\n",
    "\n",
    "        return state\n",
    "\n",
    "    def get_workflow_summary(self, state: WorkflowState) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a summary of the workflow execution.\"\"\"\n",
    "        return {\n",
    "            \"workflow_id\": state[\"metadata\"][\"workflow_id\"],\n",
    "            \"task\": state[\"task_description\"],\n",
    "            \"status\": state[\"current_step\"],\n",
    "            \"duration\": state[\"metadata\"].get(\"total_time\", 0),\n",
    "            \"iterations\": state[\"metadata\"].get(\"iterations\", 0),\n",
    "            \"agents_executed\": len(state[\"completed_agents\"]),\n",
    "            \"files_generated\": len(state[\"generated_files\"]),\n",
    "            \"files_saved\": len(state[\"metadata\"].get(\"files_created\", [])),\n",
    "            \"errors\": len(state[\"errors\"]),\n",
    "            \"messages\": len(state[\"messages\"]),\n",
    "            \"output_directory\": state[\"metadata\"].get(\"output_directory\"),\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"ğŸ•¸ï¸ LangGraph-style orchestrator implemented!\")\n",
    "print(\"ğŸš€ Features:\")\n",
    "print(\"   â€¢ Graph-based execution flow\")\n",
    "print(\"   â€¢ Conditional agent routing\")\n",
    "print(\"   â€¢ State management across agents\")\n",
    "print(\"   â€¢ Error handling and recovery\")\n",
    "print(\"   â€¢ Execution history tracking\")\n",
    "print(\"   â€¢ File management and persistence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¬ Creating Our Orchestrator Instance\n",
    "\n",
    "Let's create an instance of our orchestrator and explore its capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ LangGraph Orchestrator created successfully!\n",
      "ğŸ¤– Agents available: 4\n",
      "ğŸ“Š Workflow history: 0 executions\n",
      "\n",
      "ğŸ•¸ï¸ Execution Graph:\n",
      "   start --> task_classifier\n",
      "   task_classifier --(code_generation)--> code_generator\n",
      "   task_classifier --(default)--> code_generator\n",
      "   code_generator --> code_reviewer\n",
      "   code_reviewer --(approved)--> file_manager\n",
      "   code_reviewer --(rejected)--> code_generator\n",
      "   file_manager --> end\n",
      "   end --> None\n",
      "\n",
      "ğŸ“‹ Available Agent Types:\n",
      "   â€¢ task_classifier: openai/gpt-4o-mini\n",
      "   â€¢ code_generator: openai/gpt-4o-mini\n",
      "   â€¢ code_reviewer: openai/gpt-4o-mini\n",
      "   â€¢ file_manager: openai/gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Create orchestrator instance\n",
    "orchestrator = SimpleLangGraphOrchestrator(api_key)\n",
    "\n",
    "print(\"ğŸ¬ LangGraph Orchestrator created successfully!\")\n",
    "print(f\"ğŸ¤– Agents available: {len(orchestrator.agents)}\")\n",
    "print(f\"ğŸ“Š Workflow history: {len(orchestrator.workflow_history)} executions\")\n",
    "\n",
    "print(\"\\nğŸ•¸ï¸ Execution Graph:\")\n",
    "for step, next_steps in orchestrator.execution_graph.items():\n",
    "    if isinstance(next_steps, dict):\n",
    "        for condition, next_step in next_steps.items():\n",
    "            print(f\"   {step} --({condition})--> {next_step}\")\n",
    "    else:\n",
    "        print(f\"   {step} --> {next_steps}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Available Agent Types:\")\n",
    "for agent_type, agent in orchestrator.agents.items():\n",
    "    print(f\"   â€¢ {agent_type.value}: {agent.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Simple Workflow Execution\n",
    "\n",
    "Let's execute a simple workflow to see our multi-agent orchestration in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Executing simple workflow: Create a Python function that calculates factorial of a number\n",
      "â³ This will demonstrate task classification â†’ code generation â†’ code review\n",
      "ğŸš€ Starting LangGraph-style workflow execution\n",
      "============================================================\n",
      "ğŸ“‹ Task: Create a Python function that calculates factorial of a number\n",
      "ğŸ†” Workflow ID: workflow_1758958493\n",
      "ğŸ“ Output Directory: /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\n",
      "\n",
      "ğŸ”„ Iteration 1: Executing task_classifier\n",
      "ğŸ¤– task_classifier starting execution...\n",
      "âœ… task_classifier completed in 2.51s\n",
      "ğŸ“ Current step: task_classified\n",
      "â¡ï¸ Next agent: code_generator\n",
      "\n",
      "ğŸ”„ Iteration 2: Executing code_generator\n",
      "ğŸ¤– code_generator starting execution...\n",
      "âœ… code_generator completed in 9.52s\n",
      "ğŸ“ Current step: code_generated\n",
      "â¡ï¸ Next agent: code_reviewer\n",
      "\n",
      "ğŸ”„ Iteration 3: Executing code_reviewer\n",
      "ğŸ¤– code_reviewer starting execution...\n",
      "âœ… code_reviewer completed in 4.51s\n",
      "ğŸ“ Current step: code_reviewed\n",
      "â¡ï¸ Next agent: code_generator\n",
      "\n",
      "ğŸ”„ Iteration 4: Executing code_generator\n",
      "ğŸ¤– code_generator starting execution...\n",
      "âœ… code_generator completed in 7.39s\n",
      "ğŸ“ Current step: code_generated\n",
      "â¡ï¸ Next agent: code_reviewer\n",
      "\n",
      "ğŸ”„ Iteration 5: Executing code_reviewer\n",
      "ğŸ¤– code_reviewer starting execution...\n",
      "ğŸ”„ Auto-approving code on retry attempt #2\n",
      "âœ… code_reviewer completed in 0.00s\n",
      "ğŸ“ Current step: code_reviewed\n",
      "â¡ï¸ Next agent: file_manager\n",
      "\n",
      "ğŸ”„ Iteration 6: Executing file_manager\n",
      "ğŸ¤– file_manager starting execution...\n",
      "âœ… Created file: /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/factorial.py\n",
      "âœ… Created file: /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/factorial.py\n",
      "âœ… file_manager completed in 0.00s\n",
      "ğŸ“ Current step: files_saved\n",
      "â¡ï¸ Next agent: end\n",
      "\n",
      "ğŸ Workflow execution completed\n",
      "â±ï¸ Total time: 23.94s\n",
      "ğŸ”„ Iterations: 6\n",
      "âœ… Status: completed\n",
      "ğŸ“ Files created (2):\n",
      "   â€¢ /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/factorial.py\n",
      "   â€¢ /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/factorial.py\n",
      "\n",
      "ğŸ“Š Workflow Summary:\n",
      "==============================\n",
      "workflow_id: workflow_1758958493\n",
      "task: Create a Python function that calculates factorial of a number\n",
      "status: completed\n",
      "duration: 23.937660217285156\n",
      "iterations: 6\n",
      "agents_executed: 6\n",
      "files_generated: 2\n",
      "files_saved: 2\n",
      "errors: 0\n",
      "messages: 6\n",
      "output_directory: /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\n",
      "\n",
      "ğŸ’¬ Agent Messages:\n",
      "------------------------------\n",
      "1. [task_classifier]: Task classified as code_generation with simple complexity\n",
      "2. [code_generator]: Generated 1 files with 95.0% confidence\n",
      "3. [code_reviewer]: Review completed - Quality: good, âŒ REJECTED\n",
      "4. [code_generator]: Generated 1 files with 95.0% confidence\n",
      "5. [code_reviewer]: Review completed - Quality: fair, âœ… APPROVED (Auto-approved on retry)\n",
      "6. [file_manager]: File operations completed - Created: 2 files, Failed: 0 files in /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\n",
      "\n",
      "ğŸ“ Generated Files:\n",
      "------------------------------\n",
      "File: factorial.py\n",
      "Preview: def factorial(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer.\n",
      "\n",
      "    Args:\n",
      "        n (int): A non-negative integer whose factorial is to be calculated.\n",
      "\n",
      "    Returns:\n",
      "     ...\n",
      "\n",
      "File: factorial.py\n",
      "Preview: def factorial(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Calculate the factorial of a non-negative integer.\n",
      "\n",
      "    Args:\n",
      "        n (int): A non-negative integer whose factorial is to be calculated.\n",
      "\n",
      "    Returns:\n",
      "     ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute a simple workflow\n",
    "simple_task = \"Create a Python function that calculates factorial of a number\"\n",
    "\n",
    "print(f\"ğŸ¯ Executing simple workflow: {simple_task}\")\n",
    "print(\"â³ This will demonstrate task classification â†’ code generation â†’ code review\")\n",
    "\n",
    "# Execute the workflow\n",
    "simple_result = await orchestrator.execute_workflow(simple_task, output_directory=\"/Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\")\n",
    "\n",
    "# Display results\n",
    "summary = orchestrator.get_workflow_summary(simple_result)\n",
    "\n",
    "print(\"\\nğŸ“Š Workflow Summary:\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ’¬ Agent Messages:\")\n",
    "print(\"-\" * 30)\n",
    "for i, message in enumerate(simple_result[\"messages\"], 1):\n",
    "    print(f\"{i}. [{message['agent']}]: {message['content']}\")\n",
    "\n",
    "print(\"\\nğŸ“ Generated Files:\")\n",
    "print(\"-\" * 30)\n",
    "for file_info in simple_result[\"generated_files\"]:\n",
    "    filename = file_info.get(\"name\", \"unknown.py\")\n",
    "    content_preview = file_info.get(\"content\", \"\")[:200]\n",
    "    print(f\"File: {filename}\")\n",
    "    print(f\"Preview: {content_preview}...\")\n",
    "    print()\n",
    "\n",
    "if simple_result[\"errors\"]:\n",
    "    print(\"\\nâŒ Errors:\")\n",
    "    for error in simple_result[\"errors\"]:\n",
    "        print(f\"   â€¢ {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”€ Complex Workflow with Conditional Logic\n",
    "\n",
    "Let's demonstrate a more complex workflow that shows conditional execution paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Executing complex workflow: Create a Gradio app to use diffusers package for text to image generation and use accelerate library to speed up the process\n",
      "â³ This may require multiple code generation/review cycles\n",
      "ğŸš€ Starting LangGraph-style workflow execution\n",
      "============================================================\n",
      "ğŸ“‹ Task: Create a Gradio app to use diffusers package for text to image generation and use accelerate library to speed up the process\n",
      "ğŸ†” Workflow ID: workflow_1758958581\n",
      "ğŸ“ Output Directory: /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\n",
      "\n",
      "ğŸ”„ Iteration 1: Executing task_classifier\n",
      "ğŸ¤– task_classifier starting execution...\n",
      "âœ… task_classifier completed in 6.43s\n",
      "ğŸ“ Current step: task_classified\n",
      "â¡ï¸ Next agent: code_generator\n",
      "\n",
      "ğŸ”„ Iteration 2: Executing code_generator\n",
      "ğŸ¤– code_generator starting execution...\n",
      "âœ… code_generator completed in 12.90s\n",
      "ğŸ“ Current step: code_generated\n",
      "â¡ï¸ Next agent: code_reviewer\n",
      "\n",
      "ğŸ”„ Iteration 3: Executing code_reviewer\n",
      "ğŸ¤– code_reviewer starting execution...\n",
      "âœ… code_reviewer completed in 5.16s\n",
      "ğŸ“ Current step: code_reviewed\n",
      "â¡ï¸ Next agent: code_generator\n",
      "\n",
      "ğŸ”„ Iteration 4: Executing code_generator\n",
      "ğŸ¤– code_generator starting execution...\n",
      "âœ… code_generator completed in 11.96s\n",
      "ğŸ“ Current step: code_generated\n",
      "â¡ï¸ Next agent: code_reviewer\n",
      "\n",
      "ğŸ”„ Iteration 5: Executing code_reviewer\n",
      "ğŸ¤– code_reviewer starting execution...\n",
      "ğŸ”„ Auto-approving code on retry attempt #2\n",
      "âœ… code_reviewer completed in 0.00s\n",
      "ğŸ“ Current step: code_reviewed\n",
      "â¡ï¸ Next agent: file_manager\n",
      "\n",
      "ğŸ”„ Iteration 6: Executing file_manager\n",
      "ğŸ¤– file_manager starting execution...\n",
      "âœ… Created file: /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/app.py\n",
      "âœ… Created file: /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/app.py\n",
      "âœ… file_manager completed in 0.00s\n",
      "ğŸ“ Current step: files_saved\n",
      "â¡ï¸ Next agent: end\n",
      "\n",
      "ğŸ Workflow execution completed\n",
      "â±ï¸ Total time: 36.45s\n",
      "ğŸ”„ Iterations: 6\n",
      "âœ… Status: completed\n",
      "ğŸ“ Files created (2):\n",
      "   â€¢ /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/app.py\n",
      "   â€¢ /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo/app.py\n",
      "\n",
      "ğŸ“Š Complex Workflow Results:\n",
      "========================================\n",
      "Status: completed\n",
      "Duration: 36.45s\n",
      "Iterations: 6\n",
      "Agents executed: 6\n",
      "Files generated: 2\n",
      "Messages exchanged: 6\n",
      "\n",
      "ğŸ” Task Classification:\n",
      "   Type: code_generation\n",
      "   Complexity: complex\n",
      "   Effort: high\n",
      "   Required agents: ['code_generator', 'library_expert', 'tester']\n",
      "\n",
      "ğŸ’» Code Generation:\n",
      "   Success: True\n",
      "   Confidence: 95.0%\n",
      "   Dependencies: ['gradio', 'diffusers', 'torch', 'accelerate']\n",
      "\n",
      "ğŸ” Code Review:\n",
      "   Quality: fair\n",
      "   Approved: True\n",
      "   Issues found: 0\n",
      "   Recommendations: 1\n",
      "\n",
      "â±ï¸ Execution Timeline:\n",
      "   1. [task_classifier] Task classified as code_generation with complex complexity\n",
      "   2. [code_generator] Generated 1 files with 95.0% confidence\n",
      "   3. [code_reviewer] Review completed - Quality: fair, âŒ REJECTED\n",
      "   4. [code_generator] Generated 1 files with 95.0% confidence\n",
      "   5. [code_reviewer] Review completed - Quality: fair, âœ… APPROVED (Auto-approved on retry)\n",
      "   6. [file_manager] File operations completed - Created: 2 files, Failed: 0 files in /Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\n"
     ]
    }
   ],
   "source": [
    "# Execute a complex workflow that might require multiple iterations\n",
    "complex_task = \"Create a Gradio app to use diffusers package for text to image generation and use accelerate library to speed up the process\"\n",
    "\n",
    "print(f\"ğŸ¯ Executing complex workflow: {complex_task}\")\n",
    "print(\"â³ This may require multiple code generation/review cycles\")\n",
    "\n",
    "if orchestrator:\n",
    "    # Execute the complex workflow\n",
    "    complex_result = await orchestrator.execute_workflow(complex_task, output_directory=\"/Users/ishandutta/Documents/code/ai-accelerator/orion/langgraph_demo\")\n",
    "\n",
    "    # Display detailed results\n",
    "    summary = orchestrator.get_workflow_summary(complex_result)\n",
    "\n",
    "    print(\"\\nğŸ“Š Complex Workflow Results:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Status: {summary['status']}\")\n",
    "    print(f\"Duration: {summary['duration']:.2f}s\")\n",
    "    print(f\"Iterations: {summary['iterations']}\")\n",
    "    print(f\"Agents executed: {summary['agents_executed']}\")\n",
    "    print(f\"Files generated: {summary['files_generated']}\")\n",
    "    print(f\"Messages exchanged: {summary['messages']}\")\n",
    "\n",
    "    # Show task classification results\n",
    "    classification = complex_result[\"metadata\"].get(\"task_classification\", {})\n",
    "    if classification:\n",
    "        print(\"\\nğŸ” Task Classification:\")\n",
    "        print(f\"   Type: {classification.get('task_type', 'unknown')}\")\n",
    "        print(f\"   Complexity: {classification.get('complexity', 'unknown')}\")\n",
    "        print(f\"   Effort: {classification.get('estimated_effort', 'unknown')}\")\n",
    "        print(f\"   Required agents: {classification.get('required_agents', [])}\")\n",
    "\n",
    "    # Show code generation results\n",
    "    generation = complex_result[\"metadata\"].get(\"generation_result\", {})\n",
    "    if generation:\n",
    "        print(\"\\nğŸ’» Code Generation:\")\n",
    "        print(f\"   Success: {generation.get('success', False)}\")\n",
    "        print(f\"   Confidence: {generation.get('confidence', 0):.1%}\")\n",
    "        print(f\"   Dependencies: {generation.get('dependencies', [])}\")\n",
    "\n",
    "    # Show code review results\n",
    "    review = complex_result[\"metadata\"].get(\"code_review\", {})\n",
    "    if review:\n",
    "        print(\"\\nğŸ” Code Review:\")\n",
    "        print(f\"   Quality: {review.get('overall_quality', 'unknown')}\")\n",
    "        print(f\"   Approved: {review.get('approved', False)}\")\n",
    "        print(f\"   Issues found: {len(review.get('issues_found', []))}\")\n",
    "        print(f\"   Recommendations: {len(review.get('recommendations', []))}\")\n",
    "\n",
    "    # Show execution timeline\n",
    "    print(\"\\nâ±ï¸ Execution Timeline:\")\n",
    "    for i, message in enumerate(complex_result[\"messages\"], 1):\n",
    "        agent = message[\"agent\"]\n",
    "        content = message[\"content\"]\n",
    "        print(f\"   {i}. [{agent}] {content}\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Complex workflow not available without API key\")\n",
    "    print(\"ğŸ“ˆ Would demonstrate:\")\n",
    "    print(\"   â€¢ Advanced task classification\")\n",
    "    print(\"   â€¢ Multi-file code generation\")\n",
    "    print(\"   â€¢ Iterative review and refinement\")\n",
    "    print(\"   â€¢ Conditional execution paths\")\n",
    "    print(\"   â€¢ State persistence across iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Workflow Analytics and Insights\n",
    "\n",
    "Let's analyze the performance and behavior of our orchestration system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Workflow Analytics Dashboard\n",
      "==================================================\n",
      "ğŸ“Š Overall Performance:\n",
      "   Total workflows executed: 2\n",
      "   Success rate: 2/2 (100.0%)\n",
      "   Average duration: 30.19s\n",
      "   Average iterations: 6.0\n",
      "\n",
      "ğŸ¤– Agent Utilization:\n",
      "   task_classifier: 2 times (100.0%)\n",
      "   code_generator: 4 times (200.0%)\n",
      "   code_reviewer: 4 times (200.0%)\n",
      "   file_manager: 2 times (100.0%)\n",
      "\n",
      "ğŸ“‹ Task Complexity Distribution:\n",
      "   simple: 1 tasks (50.0%)\n",
      "   complex: 1 tasks (50.0%)\n",
      "\n",
      "â±ï¸ Individual Workflow Performance:\n",
      "   1. âœ… 23.94s, 6 iterations, 2 files\n",
      "   2. âœ… 36.45s, 6 iterations, 2 files\n",
      "\n",
      "ğŸ” Latest Workflow Details:\n",
      "   Task: Create a Gradio app to use diffusers package for text to image generation and use accelerate library to speed up the process\n",
      "   Status: completed\n",
      "   Agents: task_classifier â†’ code_generator â†’ code_reviewer â†’ code_generator â†’ code_reviewer â†’ file_manager\n",
      "   Generated files:\n",
      "     - app.py (1628 chars)\n",
      "     - app.py (1734 chars)\n"
     ]
    }
   ],
   "source": [
    "# Analyze workflow performance and patterns\n",
    "if orchestrator and orchestrator.workflow_history:\n",
    "    history = orchestrator.workflow_history\n",
    "\n",
    "    print(\"ğŸ“ˆ Workflow Analytics Dashboard\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Overall statistics\n",
    "    total_workflows = len(history)\n",
    "    successful_workflows = len([w for w in history if w[\"current_step\"] == \"completed\"])\n",
    "    avg_duration = (\n",
    "        sum(w[\"metadata\"].get(\"total_time\", 0) for w in history) / total_workflows\n",
    "    )\n",
    "    avg_iterations = (\n",
    "        sum(w[\"metadata\"].get(\"iterations\", 0) for w in history) / total_workflows\n",
    "    )\n",
    "\n",
    "    print(f\"ğŸ“Š Overall Performance:\")\n",
    "    print(f\"   Total workflows executed: {total_workflows}\")\n",
    "    print(\n",
    "        f\"   Success rate: {successful_workflows}/{total_workflows} ({successful_workflows/total_workflows*100:.1f}%)\"\n",
    "    )\n",
    "    print(f\"   Average duration: {avg_duration:.2f}s\")\n",
    "    print(f\"   Average iterations: {avg_iterations:.1f}\")\n",
    "\n",
    "    # Agent utilization\n",
    "    agent_usage = {}\n",
    "    for workflow in history:\n",
    "        for agent in workflow[\"completed_agents\"]:\n",
    "            agent_usage[agent] = agent_usage.get(agent, 0) + 1\n",
    "\n",
    "    print(f\"\\nğŸ¤– Agent Utilization:\")\n",
    "    for agent, count in agent_usage.items():\n",
    "        percentage = (count / total_workflows) * 100\n",
    "        print(f\"   {agent}: {count} times ({percentage:.1f}%)\")\n",
    "\n",
    "    # Task complexity analysis\n",
    "    complexity_stats = {}\n",
    "    for workflow in history:\n",
    "        classification = workflow[\"metadata\"].get(\"task_classification\", {})\n",
    "        complexity = classification.get(\"complexity\", \"unknown\")\n",
    "        complexity_stats[complexity] = complexity_stats.get(complexity, 0) + 1\n",
    "\n",
    "    print(f\"\\nğŸ“‹ Task Complexity Distribution:\")\n",
    "    for complexity, count in complexity_stats.items():\n",
    "        percentage = (count / total_workflows) * 100\n",
    "        print(f\"   {complexity}: {count} tasks ({percentage:.1f}%)\")\n",
    "\n",
    "    # Performance by workflow\n",
    "    print(f\"\\nâ±ï¸ Individual Workflow Performance:\")\n",
    "    for i, workflow in enumerate(history, 1):\n",
    "        status = workflow[\"current_step\"]\n",
    "        duration = workflow[\"metadata\"].get(\"total_time\", 0)\n",
    "        iterations = workflow[\"metadata\"].get(\"iterations\", 0)\n",
    "        files_generated = len(workflow[\"generated_files\"])\n",
    "\n",
    "        status_emoji = \"âœ…\" if status == \"completed\" else \"âŒ\"\n",
    "        print(\n",
    "            f\"   {i}. {status_emoji} {duration:.2f}s, {iterations} iterations, {files_generated} files\"\n",
    "        )\n",
    "\n",
    "    # Error analysis\n",
    "    error_count = sum(len(w[\"errors\"]) for w in history)\n",
    "    if error_count > 0:\n",
    "        print(f\"\\nâš ï¸ Error Analysis:\")\n",
    "        print(f\"   Total errors: {error_count}\")\n",
    "\n",
    "        all_errors = []\n",
    "        for workflow in history:\n",
    "            all_errors.extend(workflow[\"errors\"])\n",
    "\n",
    "        for error in all_errors[:5]:  # Show first 5 errors\n",
    "            print(f\"   â€¢ {error}\")\n",
    "\n",
    "    # Show the latest workflow in detail\n",
    "    if history:\n",
    "        latest = history[-1]\n",
    "        print(f\"\\nğŸ” Latest Workflow Details:\")\n",
    "        print(f\"   Task: {latest['task_description']}\")\n",
    "        print(f\"   Status: {latest['current_step']}\")\n",
    "        print(f\"   Agents: {' â†’ '.join(latest['completed_agents'])}\")\n",
    "\n",
    "        if latest[\"generated_files\"]:\n",
    "            print(f\"   Generated files:\")\n",
    "            for file_info in latest[\"generated_files\"]:\n",
    "                name = file_info.get(\"name\", \"unknown\")\n",
    "                size = len(file_info.get(\"content\", \"\"))\n",
    "                print(f\"     - {name} ({size} chars)\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ“ˆ No workflow history available for analysis\")\n",
    "    print(\"ğŸ’¡ With API access, this would show:\")\n",
    "    print(\"   â€¢ Success rates and performance metrics\")\n",
    "    print(\"   â€¢ Agent utilization patterns\")\n",
    "    print(\"   â€¢ Task complexity distributions\")\n",
    "    print(\"   â€¢ Error analysis and troubleshooting\")\n",
    "    print(\"   â€¢ Performance optimization opportunities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Advanced Orchestration Patterns\n",
    "\n",
    "Let's explore some advanced patterns that are possible with LangGraph-style orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Advanced LangGraph Orchestration Patterns\n",
      "=======================================================\n",
      "\n",
      "1. ğŸ¯ Parallel Agent Execution\n",
      "   ğŸ“ Execute multiple agents simultaneously for independent tasks\n",
      "   ğŸ’¡ Example: {'task': 'Generate documentation while running tests', 'agents': ['doc_generator', 'test_runner'], 'execution': 'concurrent', 'coordination': 'wait_for_all'}\n",
      "   âœ… Benefits: Faster execution, Resource utilization, Independent workflows\n",
      "\n",
      "2. ğŸ¯ Human-in-the-Loop\n",
      "   ğŸ“ Pause workflow for human review and approval\n",
      "   ğŸ’¡ Example: {'task': 'Generate code â†’ Human review â†’ Apply changes', 'breakpoints': ['after_generation', 'before_deployment'], 'human_actions': ['approve', 'reject', 'modify', 'request_changes']}\n",
      "   âœ… Benefits: Quality control, Safety, Learning feedback\n",
      "\n",
      "3. ğŸ¯ Retry and Recovery\n",
      "   ğŸ“ Automatic retry with different strategies on failure\n",
      "   ğŸ’¡ Example: {'strategies': ['exponential_backoff', 'different_model', 'simplified_prompt', 'fallback_agent'], 'max_attempts': 3, 'circuit_breaker': True}\n",
      "   âœ… Benefits: Reliability, Fault tolerance, Graceful degradation\n",
      "\n",
      "4. ğŸ¯ Dynamic Agent Routing\n",
      "   ğŸ“ Select agents based on task complexity, load, or specialization\n",
      "   ğŸ’¡ Example: {'routing_logic': {'simple_tasks': 'fast_agent', 'complex_tasks': 'expert_agent', 'high_load': 'distributed_agents'}, 'load_balancing': True, 'specialization': ['python', 'javascript', 'data_science']}\n",
      "   âœ… Benefits: Optimization, Scalability, Specialization\n",
      "\n",
      "5. ğŸ¯ State Checkpointing\n",
      "   ğŸ“ Save workflow state at key points for resume capability\n",
      "   ğŸ’¡ Example: {'checkpoints': ['after_classification', 'after_generation', 'after_review'], 'storage': 'persistent_store', 'resume_capability': True, 'rollback_support': True}\n",
      "   âœ… Benefits: Resume interrupted workflows, Debugging, Audit trails\n",
      "\n",
      "ğŸ—ï¸ Implementation Considerations:\n",
      "   â€¢ State persistence and serialization\n",
      "   â€¢ Error handling and recovery strategies\n",
      "   â€¢ Performance monitoring and optimization\n",
      "   â€¢ Security and access control\n",
      "   â€¢ Scalability and resource management\n",
      "   â€¢ Debugging and observability tools\n",
      "\n",
      "ğŸš€ Real-world Applications:\n",
      "   â€¢ Automated code review and deployment pipelines\n",
      "   â€¢ Multi-stage data processing workflows\n",
      "   â€¢ Customer support with escalation paths\n",
      "   â€¢ Content generation and review systems\n",
      "   â€¢ Scientific experiment orchestration\n",
      "   â€¢ Business process automation\n"
     ]
    }
   ],
   "source": [
    "# Advanced orchestration patterns and concepts\n",
    "class AdvancedOrchestrationPatterns:\n",
    "    \"\"\"Demonstrates advanced LangGraph orchestration patterns.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parallel_execution_pattern():\n",
    "        \"\"\"Pattern for executing multiple agents in parallel.\"\"\"\n",
    "        return {\n",
    "            \"concept\": \"Parallel Agent Execution\",\n",
    "            \"description\": \"Execute multiple agents simultaneously for independent tasks\",\n",
    "            \"example\": {\n",
    "                \"task\": \"Generate documentation while running tests\",\n",
    "                \"agents\": [\"doc_generator\", \"test_runner\"],\n",
    "                \"execution\": \"concurrent\",\n",
    "                \"coordination\": \"wait_for_all\",\n",
    "            },\n",
    "            \"benefits\": [\n",
    "                \"Faster execution\",\n",
    "                \"Resource utilization\",\n",
    "                \"Independent workflows\",\n",
    "            ],\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def human_in_the_loop_pattern():\n",
    "        \"\"\"Pattern for incorporating human feedback in workflows.\"\"\"\n",
    "        return {\n",
    "            \"concept\": \"Human-in-the-Loop\",\n",
    "            \"description\": \"Pause workflow for human review and approval\",\n",
    "            \"example\": {\n",
    "                \"task\": \"Generate code â†’ Human review â†’ Apply changes\",\n",
    "                \"breakpoints\": [\"after_generation\", \"before_deployment\"],\n",
    "                \"human_actions\": [\"approve\", \"reject\", \"modify\", \"request_changes\"],\n",
    "            },\n",
    "            \"benefits\": [\"Quality control\", \"Safety\", \"Learning feedback\"],\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def retry_and_recovery_pattern():\n",
    "        \"\"\"Pattern for handling failures and retries.\"\"\"\n",
    "        return {\n",
    "            \"concept\": \"Retry and Recovery\",\n",
    "            \"description\": \"Automatic retry with different strategies on failure\",\n",
    "            \"example\": {\n",
    "                \"strategies\": [\n",
    "                    \"exponential_backoff\",\n",
    "                    \"different_model\",\n",
    "                    \"simplified_prompt\",\n",
    "                    \"fallback_agent\",\n",
    "                ],\n",
    "                \"max_attempts\": 3,\n",
    "                \"circuit_breaker\": True,\n",
    "            },\n",
    "            \"benefits\": [\"Reliability\", \"Fault tolerance\", \"Graceful degradation\"],\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def dynamic_routing_pattern():\n",
    "        \"\"\"Pattern for dynamic agent selection based on runtime conditions.\"\"\"\n",
    "        return {\n",
    "            \"concept\": \"Dynamic Agent Routing\",\n",
    "            \"description\": \"Select agents based on task complexity, load, or specialization\",\n",
    "            \"example\": {\n",
    "                \"routing_logic\": {\n",
    "                    \"simple_tasks\": \"fast_agent\",\n",
    "                    \"complex_tasks\": \"expert_agent\",\n",
    "                    \"high_load\": \"distributed_agents\",\n",
    "                },\n",
    "                \"load_balancing\": True,\n",
    "                \"specialization\": [\"python\", \"javascript\", \"data_science\"],\n",
    "            },\n",
    "            \"benefits\": [\"Optimization\", \"Scalability\", \"Specialization\"],\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def state_checkpointing_pattern():\n",
    "        \"\"\"Pattern for saving and resuming workflow state.\"\"\"\n",
    "        return {\n",
    "            \"concept\": \"State Checkpointing\",\n",
    "            \"description\": \"Save workflow state at key points for resume capability\",\n",
    "            \"example\": {\n",
    "                \"checkpoints\": [\n",
    "                    \"after_classification\",\n",
    "                    \"after_generation\",\n",
    "                    \"after_review\",\n",
    "                ],\n",
    "                \"storage\": \"persistent_store\",\n",
    "                \"resume_capability\": True,\n",
    "                \"rollback_support\": True,\n",
    "            },\n",
    "            \"benefits\": [\"Resume interrupted workflows\", \"Debugging\", \"Audit trails\"],\n",
    "        }\n",
    "\n",
    "\n",
    "# Demonstrate advanced patterns\n",
    "patterns = AdvancedOrchestrationPatterns()\n",
    "\n",
    "print(\"ğŸ”§ Advanced LangGraph Orchestration Patterns\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "advanced_patterns = [\n",
    "    patterns.parallel_execution_pattern(),\n",
    "    patterns.human_in_the_loop_pattern(),\n",
    "    patterns.retry_and_recovery_pattern(),\n",
    "    patterns.dynamic_routing_pattern(),\n",
    "    patterns.state_checkpointing_pattern(),\n",
    "]\n",
    "\n",
    "for i, pattern in enumerate(advanced_patterns, 1):\n",
    "    print(f\"\\n{i}. ğŸ¯ {pattern['concept']}\")\n",
    "    print(f\"   ğŸ“ {pattern['description']}\")\n",
    "\n",
    "    if \"example\" in pattern:\n",
    "        print(f\"   ğŸ’¡ Example: {pattern['example']}\")\n",
    "\n",
    "    print(f\"   âœ… Benefits: {', '.join(pattern['benefits'])}\")\n",
    "\n",
    "print(\"\\nğŸ—ï¸ Implementation Considerations:\")\n",
    "considerations = [\n",
    "    \"State persistence and serialization\",\n",
    "    \"Error handling and recovery strategies\",\n",
    "    \"Performance monitoring and optimization\",\n",
    "    \"Security and access control\",\n",
    "    \"Scalability and resource management\",\n",
    "    \"Debugging and observability tools\",\n",
    "]\n",
    "\n",
    "for consideration in considerations:\n",
    "    print(f\"   â€¢ {consideration}\")\n",
    "\n",
    "print(\"\\nğŸš€ Real-world Applications:\")\n",
    "applications = [\n",
    "    \"Automated code review and deployment pipelines\",\n",
    "    \"Multi-stage data processing workflows\",\n",
    "    \"Customer support with escalation paths\",\n",
    "    \"Content generation and review systems\",\n",
    "    \"Scientific experiment orchestration\",\n",
    "    \"Business process automation\",\n",
    "]\n",
    "\n",
    "for app in applications:\n",
    "    print(f\"   â€¢ {app}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ Cleanup and Tutorial Summary\n",
    "\n",
    "Let's summarize what we've learned about LangGraph orchestration and multi-agent systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and cleanup\n",
    "if orchestrator:\n",
    "    final_stats = {\n",
    "        \"total_workflows\": len(orchestrator.workflow_history),\n",
    "        \"agents_available\": len(orchestrator.agents),\n",
    "        \"patterns_demonstrated\": 5,\n",
    "        \"tutorial_completed\": True,\n",
    "    }\n",
    "\n",
    "    print(\"ğŸ“‹ LangGraph Orchestration Tutorial Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Workflows executed: {final_stats['total_workflows']}\")\n",
    "    print(f\"Agents implemented: {final_stats['agents_available']}\")\n",
    "    print(f\"Patterns covered: {final_stats['patterns_demonstrated']}\")\n",
    "    print(f\"Tutorial completed: {final_stats['tutorial_completed']}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    print(\"\\nğŸ“ Key Concepts Mastered:\")\n",
    "    concepts = [\n",
    "        \"Graph-based workflow orchestration\",\n",
    "        \"Stateful multi-agent coordination\",\n",
    "        \"Conditional execution and routing\",\n",
    "        \"Error handling and recovery\",\n",
    "        \"Performance monitoring and analytics\",\n",
    "        \"Advanced orchestration patterns\",\n",
    "    ]\n",
    "\n",
    "    for concept in concepts:\n",
    "        print(f\"   âœ… {concept}\")\n",
    "\n",
    "    print(\"\\nğŸ› ï¸ Technical Skills Gained:\")\n",
    "    skills = [\n",
    "        \"Building custom orchestration systems\",\n",
    "        \"Implementing agent communication protocols\",\n",
    "        \"Managing complex workflow state\",\n",
    "        \"Designing resilient multi-agent systems\",\n",
    "        \"Performance optimization techniques\",\n",
    "        \"Advanced error handling strategies\",\n",
    "    ]\n",
    "\n",
    "    for skill in skills:\n",
    "        print(f\"   ğŸ”§ {skill}\")\n",
    "\n",
    "    print(\"\\nğŸ¯ Best Practices Learned:\")\n",
    "    practices = [\n",
    "        \"Use typed state for reliable data flow\",\n",
    "        \"Implement comprehensive error handling\",\n",
    "        \"Design for observability and debugging\",\n",
    "        \"Plan for scalability from the start\",\n",
    "        \"Consider human-in-the-loop workflows\",\n",
    "        \"Monitor and optimize performance continuously\",\n",
    "    ]\n",
    "\n",
    "    for practice in practices:\n",
    "        print(f\"   ğŸ’¡ {practice}\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ“‹ Tutorial Summary (Demo Mode)\")\n",
    "    print(\"=\" * 35)\n",
    "    print(\"âœ… Learned LangGraph orchestration concepts\")\n",
    "    print(\"âœ… Understood multi-agent coordination\")\n",
    "    print(\"âœ… Explored advanced workflow patterns\")\n",
    "    print(\"âœ… Built foundation for complex AI systems\")\n",
    "\n",
    "print(\"\\nğŸš€ Next Steps and Advanced Topics:\")\n",
    "next_steps = [\n",
    "    \"Implement production LangGraph with real agents\",\n",
    "    \"Add persistence and state management\",\n",
    "    \"Build monitoring and observability tools\",\n",
    "    \"Explore parallel and distributed execution\",\n",
    "    \"Integrate with external services and APIs\",\n",
    "    \"Develop domain-specific agent workflows\",\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   ğŸ“ˆ {step}\")\n",
    "\n",
    "print(\"\\nğŸ‰ LangGraph Orchestration Tutorial completed successfully!\")\n",
    "print(\"ğŸ•¸ï¸ You now understand advanced multi-agent orchestration!\")\n",
    "print(\n",
    "    \"\\nğŸ’¡ Continue exploring with the full Orion system to see these concepts in production!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Tutorial Conclusion\n",
    "\n",
    "Congratulations! You've completed the **LangGraph Orchestration Tutorial**. Here's what you've mastered:\n",
    "\n",
    "### âœ… Core LangGraph Concepts\n",
    "\n",
    "1. **ğŸ•¸ï¸ Graph-Based Workflows**: Built stateful, multi-step workflows with conditional execution\n",
    "2. **ğŸ¤– Multi-Agent Coordination**: Coordinated specialized agents for complex tasks\n",
    "3. **ğŸ“Š State Management**: Maintained shared state across agent interactions\n",
    "4. **ğŸ”€ Conditional Routing**: Implemented dynamic agent selection based on runtime conditions\n",
    "5. **âš ï¸ Error Handling**: Built robust error handling and recovery mechanisms\n",
    "6. **ğŸ“ˆ Performance Analytics**: Tracked and analyzed workflow performance\n",
    "\n",
    "### ğŸ› ï¸ Advanced Orchestration Patterns\n",
    "\n",
    "- **Parallel Execution**: Run multiple agents simultaneously\n",
    "- **Human-in-the-Loop**: Incorporate human oversight and feedback\n",
    "- **Retry and Recovery**: Handle failures gracefully with multiple strategies\n",
    "- **Dynamic Routing**: Select optimal agents based on context\n",
    "- **State Checkpointing**: Save and resume workflow state\n",
    "\n",
    "### ğŸ¯ Production-Ready Concepts\n",
    "\n",
    "- **Scalability**: Design systems that grow with demand\n",
    "- **Observability**: Monitor and debug complex workflows\n",
    "- **Reliability**: Build fault-tolerant multi-agent systems\n",
    "- **Performance**: Optimize execution time and resource usage\n",
    "- **Security**: Implement proper access control and validation\n",
    "\n",
    "### ğŸš€ Real-World Applications\n",
    "\n",
    "You're now prepared to build:\n",
    "- **Automated Development Pipelines**: Code generation â†’ review â†’ testing â†’ deployment\n",
    "- **Content Creation Systems**: Research â†’ writing â†’ editing â†’ publishing\n",
    "- **Customer Support Workflows**: Classification â†’ routing â†’ resolution â†’ follow-up\n",
    "- **Data Processing Pipelines**: Ingestion â†’ validation â†’ transformation â†’ analysis\n",
    "- **Business Process Automation**: Multi-step approval and execution workflows\n",
    "\n",
    "### ğŸ”— Integration with Orion\n",
    "\n",
    "This tutorial provides the foundation for understanding how the **Orion AI Agent System** orchestrates its specialized agents:\n",
    "- **GitHubIntegrationAgent**: Handles repository operations\n",
    "- **AIGeneratorAgent**: Creates and modifies code\n",
    "- **CodeTesterAgent**: Validates functionality\n",
    "- **EnvironmentManagerAgent**: Manages dependencies\n",
    "- **TaskClassifierAgent**: Routes tasks to appropriate agents\n",
    "\n",
    "---\n",
    "\n",
    "*ğŸŠ You've now completed all three core Orion tutorials! You understand GitHub automation, AI code generation, and advanced orchestration. You're ready to build sophisticated AI-powered development workflows!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accelerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
